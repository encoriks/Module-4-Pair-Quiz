---
title: "Module 4 Pair Quiz"
author: "Atienza, Dizon E"
date: "7/30/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question 1

#### An article in the *Journal of Sound and Vibration* ["Measurement of Noise-Evoked Blood Pressure by Means of Averaging Method: Relation between Blood Pressure Rise and PSL" (1991, Vol. 151(3), pp. 383-394)] described a study investigating the relationship between noise exposure and hypertension. The following data are representative of those reported in the article.

![](Images/Graph 1.png)

### A. Draw a scatter diagram of y (blood pressure rise in millimeters of mercury) versus x (sound pressure level in decibels). Does a simple linear regression model seem reasonable in this situation?

A simple scatter plot diagram of the values listed in the table can be seen below:

```{r, echo=FALSE}
x <- c(60, 63, 65, 70, 70, 70, 80, 90, 80, 80, 85, 89, 90, 90, 90, 90, 94, 100, 100, 100)
y <- c(1, 0, 1, 2, 5, 1, 4, 6, 2, 3, 5, 4, 6, 8, 4, 5, 7, 9, 7, 6)
plot(x,y, pch=16, cex=1.2, col="blue", main="Blood Pressure vs Sound Pressure", xlab="Blood Pressure Rise (in mmHg)", ylab="Sound Pressure Level (in dB)")
```

Based on the given table, a straight line is not immediately obvious, but there is an upwards trend. This is enough reason to utilize a linear regression model.

### B. Fit the simple linear regression model using least squares. Find an estimate of $σ^2$

To use the least squares method, we first establish the equation of a line: $y=mx+b$

Where:

- **y** = The point on the y-axis
- **m** = Is the magnitude of the slope
- **x** = The point on the x-axis
- **b** = The y intercept

The general equation for **m**, or the slope, where **N** is the number of values is shown below:
$$m=\frac{N\sum(xy)-\sum x\sum y}{N\sum(x^2)-(\sum x)^2}$$

```{r, echo=FALSE}
library(knitr)
x <- c(60, 63, 65, 70, 70, 70, 80, 90, 80, 80, 85, 89, 90, 90, 90, 90, 94, 100, 100, 100)
y <- c(1, 0, 1, 2, 5, 1, 4, 6, 2, 3, 5, 4, 6, 8, 4, 5, 7, 9, 7, 6)
sums <- data.frame(x, y, x^2, x*y)
kable(sums, "pipe", col.names=c("$x$", "$y$", "$x^2$", "$xy$"), align=c("l", "l", "l", "l"), caption="Values needed for the equation:")
```

We can then find the sum of each of the values.

- $\sum x = 1656$
- $\sum y = 86$
- $\sum x^2 = 140176$
- $\sum xy = 7654$

Then we can proceed to plugging in the values with **N=20**, which results in the following equation:
$$m=\frac{20(7654)-(1656)(86)}{20(140176)-1656^2}=0.1742939331\approx 0.174$$

To find the value of **b**, we will utilize the equation:
$$b=\frac{\sum y-m\sum x}{N}$$

Plugging in the values we previously obtained:
$$b=\frac{86-(0.174)(1656)}{20}=-10.1072\approx-10.107$$

Giving us the linear equation:
$$y=0.174x - 10.107$$

The resulting line on the scatter plot can be seen below:

```{r, echo=FALSE}
x <- c(60, 63, 65, 70, 70, 70, 80, 90, 80, 80, 85, 89, 90, 90, 90, 90, 94, 100, 100, 100)
y <- c(1, 0, 1, 2, 5, 1, 4, 6, 2, 3, 5, 4, 6, 8, 4, 5, 7, 9, 7, 6)
plot(x,y, pch=16, cex=1.2, col="blue", main="Blood Pressure vs Sound Pressure", xlab="Blood Pressure Rise (in mmHg)", ylab="Sound Pressure Level (in dB)")
abline(-10.107, 0.174, col="orange")

```

In order to find $\sigma^2$, we will use the unbiased estimator. The equation of which is seen below:
$$\sigma^2=\frac{SS_E}{n-p}$$

We can also utilize r to find $\sigma^2$.

```{r}
x <- c(60, 63, 65, 70, 70, 70, 80, 90, 80, 80, 85, 89, 90, 90, 90, 90, 94, 100, 100, 100)
y <- c(1, 0, 1, 2, 5, 1, 4, 6, 2, 3, 5, 4, 6, 8, 4, 5, 7, 9, 7, 6)
yline <- c(0.174 * x)-10.107
sig <- (sum((y-yline)^2))/18
sig
```

By inputting the values of y in the calculated line, and subtracting them by the original line and getting the sum of that then squaring it, we can find $SS_E$. By calculating this using r, we get the value $1.737041 \approx 1.737$. 
$$\sigma^2=1.737$$

### C. Find the predicted mean rise in blood pressure level associated with a sound pressure level of 85 decibels.

To find the predicted mean rise in blood pressure level at 85 decibels, we simply input 85 to the value of x in the linear equation:
$$y=0.174(85)-10.107=4.683$$

So we are given a value of 4.683, which is the predicted rise in blood pressure level when the sound pressure is at 85 decibels.

## Question 2

#### An article in *Optical Engineering* ["Operating Curve Extraction of a Correlator's Filter" (2004, Vol. 43, pp. 2775-2779)] reported on the use of an optical correlator to perform an experiment by varying brightness and contrast. The resulting modulation is characterized by the useful range of gray levels. The data follow:

![](Images/Graph 2.png)

### A. Fit a multiple linear regression model to these data.

We first plot the given data points. Then, we use the lm function in R to find the multiple regression model of our data set. This gives us the necessary scatter plots and data to solve the succeeding questions.

```{r, echo=FALSE}
oc.data <- data.frame(
  Brightness = c(54, 61, 65, 100, 100, 100, 50, 57, 54),
  Contrast = c(56, 80, 70, 50, 65, 80, 25, 35, 26),
  UsefulRange = c(96, 50, 50, 112, 96, 80, 155, 144, 255))

plot(oc.data)
```

```{r}
multiple.regression <- lm(UsefulRange ~ Brightness + Contrast, data=oc.data)
summary(multiple.regression)
```

From there, we can now use the coefficients above to form the multiple linear regression model below. This gives us the following equation:

$$y = Intercept+CoeffBrightness(X_1)+CoeffContrast(X_2)$$

$$Useful Range = 238.5569+(0.3339)(X_1)+(-2.7167)(X_2)$$

### B. Estimate $σ^2$.

To estimate $σ^2$, we utilize the following formula: 
$$σ^2 = \frac{SS_E}{n-(k+1)}$$

To find SSE, we will utilize r:

```{r}
Brightness <- c(54, 61, 65, 100, 100, 100, 50, 57, 54)
Contrast <- c(56, 80, 70, 50, 65, 80, 25, 35, 26)
UsefulRange = c(96, 50, 50, 112, 96, 80, 155, 144, 255)
yhat <- c(238.5569 + (0.3339*Brightness) + (-2.7167*Contrast))
sse <- sum((UsefulRange-yhat)^2)
sse
```
We then input the values to the equation:
$$\sigma^2=\frac{7927.636}{9-(2+1)}=1321.27267\approx1321.273$$

So plugging in the values into the equation, we end up with 1321.273. Therefore:
$$\sigma^2=1321.273$$

We can verify this by taking its square root and seeing if it equates to the residual standard error from the multiple regression summary which is 36.35.
$$\sigma=\sqrt{1321.273}=36.3493191\approx36.35$$

### C. Compute the standards of errors of the regression coefficients. 

Taking from to the data generated by the lm function, the standards of errors of the regression coefficients are as follows:

$$Brightness=0.6763$$
$$Contrast=0.6887$$  

### D. Predict the useful range when brightness = 80 and contrast = 75.

Again, to find the useful range when brightness = 80 and contrast = 75, we simply input 80 and 75 to the values of $X_1$ and $X_2$ in the linear equation respectively:

$$Useful Range = 238.5569+(0.3339)(80)+(-2.7167)(75)$$
This gives us a value of 61.5164, which serves as the useful range given brightness level = 80 and contrast level = 75.

### E. Test for significance of regression using $α=0.05$. What is the P-value for this test?

To test for significance of regression, we simply use the p-value from the data above which gives us 0.01459.  

Then, we = compare this to alpha = 0.05

$$0.01459 < 0.05$$
Since the p-value is less than alpha = 0.05, we can conclude that the regression is significant and can be observed between the values.

### F. Construct a t-test on each regression coefficient. What conclusions can you draw about the variables in this model? Use $α=0.05$.

We begin by formulating the null and alternative hypotheses:
$$H_o: β_1 = 0$$
$$H_a: β_1 >0$$

The null hypothesis shows that $β_1$ is equal to 0, meaning that there is no relationship, while the alternative hypothesis shows that $β_1$ is greater than 0, meaning that there is a strong relation ship with the regression.

We will first test for brightness. To do this, we will use the equation:
$$t=\frac{b_1-0}{S_E}$$

Plugging in the values previously calculated, we end up with the following equation:
$$t=\frac{0.3339}{0.6763}=0.49371$$

We use r once again to find the p-value.

```{r}
pt(0.49371, 8)
```

Since the p-value obtained from this is greater than 0.05, then we fail to reject the null hypothesis, which means that brightness is not a good predictor of the regression model.

We will then test for the variable of contrast and we plug in the previously obtained values into the same equation to find the t-score for contrast:
$$t=\frac{-2.7167}{0.6887}=-3.94467838$$

We then use the pt function of r again to find its p-value.

```{r}
pt(-3.94467838, 8)
```

And we end up with a value which is much lower than 0.05. Since $0.002 < α$, then we reject the null hypothesis, leading us to accept the alternative hypothesis. This means that contrast is a good predictor of the regression model.

***

References:

5.3 - The Multiple Linear Regression Model | STAT 462. (2018). https://online.stat.psu.edu/stat462/node/131/?fbclid=IwAR1Ab_w7WPtjSOIYQFc99fO0RWozsG77DQG9D3CmndnU3437-256R_nE4KA. 

Lillis, D. (2020, November 3). Linear models in R: Plotting regression lines. The Analysis Factor. https://www.theanalysisfactor.com/linear-models-r-plotting-regression-lines/. 

Montgomery, D. C., &amp; Runger, G. C. (2019). Multiple Linear Regression. In Applied statistics and probability for engineers (7th ed., pp. 310–350). essay, Wiley. 
